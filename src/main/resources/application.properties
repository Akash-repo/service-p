spring.application.name=service-p

server.port=8083

# Docker DB
spring.datasource.url=jdbc:postgresql://localhost:5432/postgres
spring.datasource.username=postgres
spring.datasource.password=mysecretpostgrespassword
spring.datasource.driver-class-name=org.postgresql.Driver
spring.jpa.hibernate.ddl-auto=update
# Use 'update' for development, 'none' or 'validate' for production
spring.jpa.show-sql=true
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect

# --- Kafka Producer Configuration (for KafkaTemplate) ---
# These are Spring Kafka's autoconfiguration properties.
# They will use the values defined in our custom 'kafka.producer' section below.
spring.kafka.bootstrap-servers=${kafka.producer.bootstrap-servers}
spring.kafka.producer.key-serializer=${kafka.producer.key-serializer}
spring.kafka.producer.value-serializer=${kafka.producer.value-serializer}
spring.kafka.producer.acks=${kafka.producer.acks}
spring.kafka.producer.retries=${kafka.producer.max-retries}
spring.kafka.producer.properties.linger.ms=${kafka.producer.linger-ms}
spring.kafka.producer.properties.batch.size=${kafka.producer.batch-size}

# This is crucial for Confluent's KafkaAvroSerializer/Deserializer
spring.kafka.properties.schema.registry.url=${kafka.producer.schema-registry-url}

# --- Custom KafkaProducerProperties Binding ---
# These properties directly bind to your com.interview.service_p.config.KafkaProducerProperties class.
# Ensure all fields in that class have corresponding entries here.
kafka.producer.topic-name=ticker-analysis-requests
kafka.producer.dlt-topic-name=ticker-analysis-requests.DLT
kafka.producer.max-retries=3
kafka.producer.retry-delay-ms=1000
kafka.producer.bootstrap-servers=localhost:29092
kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
kafka.producer.value-serializer=io.confluent.kafka.serializers.KafkaAvroSerializer
kafka.producer.acks=all
kafka.producer.linger-ms=10
kafka.producer.batch-size=16384
kafka.producer.schema-registry-url=http://localhost:8081



# Configure Avro deserialization for the message value
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer

# Schema Registry URL - IMPORTANT!
spring.kafka.consumer.properties.schema.registry.url=http://localhost:8081
spring.kafka.consumer.properties.specific.avro.reader=true
# Redis Configuration
spring.data.redis.host=localhost
spring.data.redis.port=6379
# spring.data.redis.password=your_redis_password # Uncomment if Redis requires a password

# External REST API Configuration (using the new "rest.api" prefix)
rest.api.providers.fmp.base-url=https://financialmodelingprep.com/api
rest.api.providers.fmp.api-key=YOUR_FMP_API_KEY # REPLACE WITH YOUR ACTUAL FMP API KEY
rest.api.providers.fmp.resource-path=/v3/quote/{ticker}
rest.api.providers.fmp.max-retries=3
rest.api.providers.fmp.retry-delay-ms=500
rest.api.providers.fmp.timeout-ms=5000
rest.api.providers.fmp.db-staleness-threshold-minutes=240
# Data in DB considered stale after 4 hours, forcing API call

# Example for another provider (if you add one later)
# rest.api.providers.alpha-vantage.base-url=https://www.alphavantage.co/query
# rest.api.providers.alpha-vantage.api-key=YOUR_ALPHA_VANTAGE_API_KEY
# rest.api.providers.alpha-vantage.stock-quote-endpoint=function=GLOBAL_QUOTE&symbol={ticker}&apikey=
# rest.api.providers.alpha-vantage.max-retries=2
# rest.api.providers.alpha-vantage.retry-delay-ms=1000
# rest.api.providers.alpha-vantage.timeout-ms=8000
# rest.api.providers.alpha-vantage.db-staleness-threshold-minutes=1440
# 24 hours